{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSGO Win Probability Model Tuning\n",
    "##### Peter Xenopoulos\n",
    "##### January 31, 2020\n",
    "This Jupyter notebook contains the code for model tuning. You will find the model fitting and tuning procedures for (1) Logistic Regression, (2) XGBoost and (3) CatBoost. Final models are saved to the `models` directory. You can load models using the `.load_model()` method. The data in the `data/` directory is an example of a few matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from catboost import Pool, CatBoost, CatBoostClassifier, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define our random seed and our cutoff date. Matches before and on the cutoff date comprise the training set. Matches after comprise the test set.\n",
    "\n",
    "We also create two lists of columns. The first, without the `_CB` in the name, indicates variables that have been one hot encoded. This is necessary for XGBoost and Logistic Regression.\n",
    "\n",
    "Finally, we read in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "RANDOM_STATE = 2020\n",
    "CUTOFF_DATE = \"2019-12-15\"\n",
    "\n",
    "# One Hot Encoded columns\n",
    "COLS_ALL = [\"MapName_de_dust2\", \"MapName_de_inferno\", \"MapName_de_mirage\", \"MapName_de_nuke\", \"MapName_de_overpass\", \"MapName_de_train\", \"MapName_de_vertigo\",\n",
    "       \"TicksSinceStart\", \"CTEqVal\", \"TEqVal\", \"TRemaining\", \"CTRemaining\", \"THpRemaining\", \"CTHpRemaining\", \"BombPlanted\", \"CTDistBombsiteA\", \"CTDistBombsiteB\", \"TDistBombsiteA\", \"TDistBombsiteB\"]\n",
    "COLS_NO_SPATIAL = [\"MapName_de_dust2\", \"MapName_de_inferno\", \"MapName_de_mirage\", \"MapName_de_nuke\", \"MapName_de_overpass\", \"MapName_de_train\", \"MapName_de_vertigo\",\n",
    "       \"TicksSinceStart\", \"CTEqVal\", \"TEqVal\", \"TRemaining\", \"CTRemaining\", \"THpRemaining\", \"CTHpRemaining\", \"BombPlanted\"]\n",
    "\n",
    "# Non-encoded columns\n",
    "COLS_CB_ALL = [\"MapName\", \"TicksSinceStart\", \"CTEqVal\", \"TEqVal\", \"TRemaining\", \"CTRemaining\", \"THpRemaining\", \"CTHpRemaining\", \"BombPlanted\", \"CTDistBombsiteA\", \"CTDistBombsiteB\", \"TDistBombsiteA\", \"TDistBombsiteB\"]\n",
    "COLS_CB_NO_SPATIAL = [\"MapName\", \"TicksSinceStart\", \"CTEqVal\", \"TEqVal\", \"TRemaining\", \"CTRemaining\", \"THpRemaining\", \"CTHpRemaining\", \"BombPlanted\"]\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(\"data/example_matches.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we preprocess the data, creating some one hot encoded columns. Next, we split into the test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess columns\n",
    "df[\"GameDate\"] = pd.to_datetime(df[\"GameDate\"])\n",
    "map_names = df[\"MapName\"]\n",
    "df = pd.get_dummies(df, columns = [\"MapName\"], drop_first = False)\n",
    "df[\"MapName\"] = map_names\n",
    "#df = pd.get_dummies(df, columns = [\"BombSite\"], drop_first = False)\n",
    "#df.drop(columns = [\"BombSite_NotPlanted\"], inplace = True)\n",
    "\n",
    "# Train/Test split\n",
    "train_df = df[df[\"GameDate\"] < CUTOFF_DATE]\n",
    "test_df = df[df[\"GameDate\"] >= CUTOFF_DATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split the data into the various design matrices, as well as dropping NAs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Data used in logistic regression and XGBoost\n",
    "train_df.dropna(subset = COLS_ALL, inplace=True)\n",
    "X_train_ALL = train_df[COLS_ALL]\n",
    "X_train_NO_SPATIAL = train_df[COLS_NO_SPATIAL]\n",
    "y_train = train_df[\"CTWin\"]\n",
    "\n",
    "test_df.dropna(subset = COLS_ALL, inplace=True)\n",
    "X_test_ALL = test_df[COLS_ALL]\n",
    "X_test_NO_SPATIAL = test_df[COLS_NO_SPATIAL]\n",
    "y_test = test_df[\"CTWin\"]\n",
    "\n",
    "# Data used in CatBoost\n",
    "train_df.dropna(subset = COLS_CB_ALL, inplace=True)\n",
    "X_train_cb_ALL = train_df[COLS_CB_ALL]\n",
    "X_train_cb_NO_SPATIAL = train_df[COLS_CB_NO_SPATIAL]\n",
    "y_train_cb = train_df[\"CTWin\"]\n",
    "\n",
    "test_df.dropna(subset = COLS_CB_ALL, inplace=True)\n",
    "X_test_cb_ALL = test_df[COLS_CB_ALL]\n",
    "X_test_cb_NO_SPATIAL = test_df[COLS_CB_NO_SPATIAL]\n",
    "y_test_cb = test_df[\"CTWin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print Function\n",
    "We use this print function to print the train/test results of our best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true_labels, y_pred_probs):\n",
    "    \"\"\" Presents performance info\n",
    "    \"\"\"\n",
    "    print(\"---------- LOG LOSS\")\n",
    "    print(log_loss(y_true_labels, y_pred_probs))\n",
    "    print(\"---------- BRIER SCORE\")\n",
    "    print(brier_score_loss(y_true_labels, y_pred_probs[:,1]))\n",
    "    print(\"---------- AUC\")\n",
    "    print(roc_auc_score(y_true_labels, y_pred_probs[:,1]))\n",
    "    print(\"---------- ACCURACY\")\n",
    "    print(accuracy_score(y_true_labels, y_pred_probs[:,1] >= 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Win Rate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses the mean CT win percentage as its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- LOG LOSS\n",
      "0.6939758480193727\n",
      "---------- BRIER SCORE\n",
      "0.2504143067921506\n",
      "---------- AUC\n",
      "0.5\n",
      "---------- ACCURACY\n",
      "0.4729157960196518\n"
     ]
    }
   ],
   "source": [
    "test_df[\"BaselinePred\"] = train_df.CTWin.mean()\n",
    "print_results(test_df[\"CTWin\"], np.column_stack((1 - test_df[\"BaselinePred\"], test_df[\"BaselinePred\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Average Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses the mean CT win percentage, by map, as its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_map(train, test):\n",
    "    \"\"\" Create a baseline map performance\n",
    "    \"\"\"\n",
    "    # Generate map win percentages\n",
    "    map_win_rate = train.groupby(\"MapName\").CTWin.mean().reset_index()\n",
    "    map_win_rate.columns = [\"MapName\", \"PredWinRate\"]\n",
    "    # Can't do a big join locally, so break it up by map\n",
    "    test[\"PredMapWinRate\"] = 0.5\n",
    "    map_subset_df = []\n",
    "    for map_name in test[\"MapName\"].unique():\n",
    "        subset_map = test[test[\"MapName\"] == map_name]\n",
    "        subset_map[\"PredMapWinRate\"] = map_win_rate[map_win_rate[\"MapName\"] == map_name].PredWinRate.values[0]\n",
    "        map_subset_df.append(subset_map)\n",
    "    test = pd.concat(map_subset_df)\n",
    "    print_results(test[\"CTWin\"], np.column_stack((1 - test[\"PredMapWinRate\"], test[\"PredMapWinRate\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- LOG LOSS\n",
      "0.69507021638641\n",
      "---------- BRIER SCORE\n",
      "0.25095784919869124\n",
      "---------- AUC\n",
      "0.5157164845053701\n",
      "---------- ACCURACY\n",
      "0.4852771506897524\n"
     ]
    }
   ],
   "source": [
    "baseline_map(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present the logistic regression results on two feature sets, one using all features available and the other using no spatial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- LOG LOSS\n",
      "0.5562906469600253\n",
      "---------- BRIER SCORE\n",
      "0.19179454216780603\n",
      "---------- AUC\n",
      "0.7749967100788642\n",
      "---------- ACCURACY\n",
      "0.6962260076343663\n"
     ]
    }
   ],
   "source": [
    "lr_all = LogisticRegression(random_state=2020).fit(X_train_ALL, y_train)\n",
    "lr_all_test_probs = lr_all.predict_proba(X_test_ALL)\n",
    "\n",
    "print_results(y_test, lr_all_test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pxenopoulos/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- LOG LOSS\n",
      "0.5707958001623034\n",
      "---------- BRIER SCORE\n",
      "0.19715591697605758\n",
      "---------- AUC\n",
      "0.7631896975936451\n",
      "---------- ACCURACY\n",
      "0.6887905988118542\n"
     ]
    }
   ],
   "source": [
    "lr_no_spatial = LogisticRegression(random_state=2020).fit(X_train_NO_SPATIAL, y_train)\n",
    "lr_no_spatial_test_probs = lr_no_spatial.predict_proba(X_test_NO_SPATIAL)\n",
    "\n",
    "print_results(y_test, lr_no_spatial_test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present the XGBoost results on two feature sets, one using all features available and the other using no spatial features.\n",
    "\n",
    "We search over the parameter space below, using grid search with 5-fold cross validation and a log loss scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = { \n",
    " \"max_depth\"        : [6, 8, 10, 12, 14],\n",
    " \"colsample_bytree\" : [0.2, 0.4, 0.6, 0.8],\n",
    " \"learning_rate\"    : [0.01, 0.05, 0.1, 0.2],\n",
    " \"min_child_weight\" : [1, 3, 5, 7]}\n",
    "\n",
    "xgb_kfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n",
    "xgb = XGBClassifier(n_estimators=100, objective=\"logloss\", tree_method=\"gpu_hist\", gpu_id=0)\n",
    "\n",
    "xgb_cv = GridSearchCV(xgb, param_grid=xgb_params, cv=xgb_kfold, scoring=\"neg_log_loss\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv.fit(X_train_ALL, y_train)\n",
    "xgb_all = xgb_cv.best_estimator_\n",
    "xgb_all.save_model(\"models/xgboost_all_features.model\")\n",
    "print(xgb_cv.best_params_)\n",
    "xgb_all_test_probs = xgb_all.predict_proba(X_test_ALL)\n",
    "print_results(y_test, xgb_all_test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv.fit(X_train_NO_SPATIAL, y_train)\n",
    "xgb_no_spatial = xgb_cv.best_estimator_\n",
    "xgb_no_spatial.save_model(\"models/xgboost_no_spatial_features.model\")\n",
    "print(xgb_cv.best_params_)\n",
    "xgb_no_spatial_test_probs = xgb_no_spatial.predict_proba(X_test_NO_SPATIAL)\n",
    "print_results(y_test, xgb_no_spatial_test_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present the XGBoost results on two feature sets, one using all features available and the other using no spatial features.\n",
    "\n",
    "We search over the parameter space below, using grid search with 5-fold cross validation and a log loss scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {\n",
    "    \"learning_rate\": [0.05, 0.1, 0.5, 1],\n",
    "    \"depth\": [6, 8, 10, 12, 14],\n",
    "    \"l2_leaf_reg\": [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "cb_kfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)\n",
    "cb_all_pool = Pool(data = X_train_cb_ALL, label = y_train_cb, cat_features = [0])\n",
    "cb_no_spatial_pool = Pool(data = X_train_cb_NO_SPATIAL, label = y_train_cb, cat_features = [0])\n",
    "\n",
    "cb = CatBoostClassifier(iterations=100, task_type=\"GPU\", devices=\"0:1\", custom_metric=[\"Logloss\"])\n",
    "\n",
    "cb_cv = GridSearchCV(cb, param_grid=cb_params, cv=cb_kfold, scoring=\"neg_log_loss\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_cv.fit(X_train_cb_ALL, y_train, cat_features = [0])\n",
    "cb_all = cb_cv.best_estimator_\n",
    "cb_all.save_model(\"models/catboost_all_features.model\", \"cbm\")\n",
    "print(cb_cv.best_params_)\n",
    "cb_all_test_probs = cb_all.predict_proba(X_test_cb_ALL)\n",
    "print_results(y_test, cb_all_test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_cv.fit(X_train_cb_NO_SPATIAL, y_train, cat_features = [0])\n",
    "cb_no_spatial = cb_cv.best_estimator_\n",
    "cb_no_spatial.save_model(\"models/catboost_no_spatial_features.model\", \"cbm\")\n",
    "print(cb_cv.best_params_)\n",
    "cb_no_spatial_test_probs = cb_no_spatial.predict_proba(X_test_cb_NO_SPATIAL)\n",
    "print_results(y_test, cb_no_spatial_test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add bombsite, fix col names and cat features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
